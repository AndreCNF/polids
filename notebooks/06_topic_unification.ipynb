{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a038bd6",
   "metadata": {},
   "source": [
    "# Political topic unification\n",
    "---\n",
    "Testing the merging of political topics into high-level, concise topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f82055",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68012ac",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dbf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polids.config import settings\n",
    "from polids.utils.text_similarity import compute_text_similarity_scores\n",
    "from polids.topic_unification.openai import OpenAITopicUnifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e316f2c6",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"# Role\n",
    "You are a political data analyst specialized in categorizing policy areas into standardized, concise supercategories for downstream analysis.\n",
    "\n",
    "# Objective\n",
    "Process a list of political topics with frequency counts to:\n",
    "1. Generate concise, high-level policy categories (unified topics).\n",
    "2. Map each input topic to its corresponding unified category.\n",
    "3. Output the results as structured JSON following a defined schema.\n",
    "\n",
    "# Input Format\n",
    "A list where each line contains a topic and its frequency, separated by |. The list is pre-sorted in descending order by frequency.\n",
    "```markdown\n",
    "- Topic String 1 | Frequency 1\n",
    "- Topic String 2 | Frequency 2\n",
    "...\n",
    "- Topic String N | Frequency N\n",
    "```\n",
    "\n",
    "# Task\n",
    "1. **Parse Input:** Extract the topic string and frequency integer from each line of the input markdown list. The topic string alone will be used as the key in the output mapping.\n",
    "2. **Cluster Semantically:** Group input topics that share core concepts, address related issues, or belong to a clear broader policy domain. Use the descending frequency order as a strong signal for identifying core themes, but prioritize semantic coherence.\n",
    "3. **Define Unified Topics:** For each cluster, create a single, concise name for the unified topic.\n",
    "4. **Map Inputs:** Assign each input topic string to exactly one unified topic name.\n",
    "5. **Generate Output:** Format the results according to the specified JSON schema.\n",
    "\n",
    "# Guidelines\n",
    "- **Conciseness:** Unified topic names must be 1-5 words. (e.g., \"Economy\", \"Healthcare\", \"Climate Action\").\n",
    "- **Mutual Exclusivity:** Unified topics must be distinct and non-overlapping in scope. Each input topic must map to only one unified topic.\n",
    "- **Comprehensiveness:** All input topics must be mapped to a unified topic.\n",
    "- **Political Relevance:** Use standard political science or common policy terminology for unified topic names.\n",
    "- **Balance:** Aim for a reasonable number of unified topics (typically 5-12) â€“ avoid over-granularity or excessive consolidation.\n",
    "\n",
    "# Example\n",
    "## Input\n",
    "- Environmental Protection | 20\n",
    "- Economic Growth Initiatives | 18\n",
    "- Immigration reform | 17\n",
    "- Climate Change Policies | 16\n",
    "- Healthcare for All | 15\n",
    "- Job creation programs | 14\n",
    "- Strengthen military | 13\n",
    "- Universal Healthcare Coverage | 12\n",
    "- Improve public schools | 11\n",
    "- Sustainable Economic Development | 10\n",
    "- Border security funding | 10\n",
    "- Renewable energy subsidies | 9\n",
    "- Lower prescription drug costs | 8\n",
    "- Reduce corporate tax rate | 7\n",
    "- Affordable higher education | 6\n",
    "- Combat Global Warming | 5\n",
    "- Foreign aid reform | 4\n",
    "##Output\n",
    "{\n",
    "  \"unified_topics\": [\n",
    "    \"Climate Action\",\n",
    "    \"Economy\",\n",
    "    \"Immigration & Border Security\",\n",
    "    \"Healthcare\",\n",
    "    \"Education\",\n",
    "    \"Defense & Foreign Policy\"\n",
    "  ],\n",
    "  \"topic_mapping\": {\n",
    "    \"Environmental Protection\": \"Climate Action\",\n",
    "    \"Economic Growth Initiatives\": \"Economy\",\n",
    "    \"Immigration reform\": \"Immigration\",\n",
    "    \"Climate Change Policies\": \"Climate Action\",\n",
    "    \"Healthcare for All\": \"Healthcare\",\n",
    "    \"Job creation programs\": \"Economy\",\n",
    "    \"Strengthen military\": \"Defense & Foreign Policy\",\n",
    "    \"Universal Healthcare Coverage\": \"Healthcare\",\n",
    "    \"Improve public schools\": \"Education\",\n",
    "    \"Sustainable Economic Development\": \"Economy\",\n",
    "    \"Border security funding\": \"Immigration\",\n",
    "    \"Renewable energy subsidies\": \"Climate Action\",\n",
    "    \"Lower prescription drug costs\": \"Healthcare\",\n",
    "    \"Reduce corporate tax rate\": \"Economy\",\n",
    "    \"Affordable higher education\": \"Education\",\n",
    "    \"Combat Global Warming\": \"Climate Action\",\n",
    "    \"Foreign aid reform\": \"Defense & Foreign Policy\"\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_retries = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_topic(input_topic: str, topic_mapping: dict[str, list[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Maps the input topic to its corresponding unified topic using the provided mapping.\n",
    "    If the input topic is not found in the mapping, it returns the most similar topic,\n",
    "    based on character-based and semantic similarity.\n",
    "\n",
    "    Args:\n",
    "        input_topic (str): The topic to be mapped.\n",
    "        topic_mapping (dict[str, list[str]]): A dictionary mapping output topics to input topics.\n",
    "\n",
    "    Returns:\n",
    "        str: The mapped topic.\n",
    "    \"\"\"\n",
    "    mapped_output_topics = []\n",
    "    for output_topic, input_topics in topic_mapping.items():\n",
    "        for input_topic_ in input_topics:\n",
    "            if input_topic == input_topic_:\n",
    "                # Add the exact match to the list of mapped output topics\n",
    "                # (note that we don't have a guarantee that there is only one exact match)\n",
    "                mapped_output_topics.append(output_topic)\n",
    "    if len(mapped_output_topics) == 1:\n",
    "        return mapped_output_topics[0]\n",
    "    elif len(mapped_output_topics) > 1:\n",
    "        # Compare the mapped output topics to find the most similar one\n",
    "        output_topics_to_compare = mapped_output_topics\n",
    "    else:\n",
    "        # Compare all output topics to find the most similar one\n",
    "        output_topics_to_compare = list(topic_mapping.keys())\n",
    "    output_topic_similarity_scores = {\n",
    "        output_topic: np.mean(compute_text_similarity_scores(input_topic, output_topic))\n",
    "        for output_topic in output_topics_to_compare\n",
    "    }\n",
    "    # Return the output topic with the highest similarity score\n",
    "    return max(\n",
    "        output_topic_similarity_scores,\n",
    "        # Compare each dictionary key based on their average similarity score\n",
    "        # and return the one with the highest score\n",
    "        key=output_topic_similarity_scores.get,  # type: ignore\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380113cc",
   "metadata": {},
   "source": [
    "## Load topics to merge\n",
    "We're going to use manually defined topics, so as to avoid dependencies on previous steps of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed47a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_to_unify = {\n",
    "    # Social Issues / Civil Rights\n",
    "    \"Protecting LGBTQ+ rights\": 18,\n",
    "    \"Ensuring voting access for all\": 25,\n",
    "    \"Criminal justice reform initiatives\": 22,\n",
    "    \"Addressing systemic racism\": 15,\n",
    "    \"Defending Second Amendment freedoms\": 28,\n",
    "    \"Common-sense gun safety laws\": 26,\n",
    "    \"Protecting freedom of religion\": 12,\n",
    "    \"Police funding and accountability\": 19,\n",
    "    \"Reproductive healthcare access\": 23,\n",
    "    # Technology & Infrastructure\n",
    "    \"Expanding rural broadband internet\": 16,\n",
    "    \"Investing in national infrastructure (roads, bridges)\": 30,\n",
    "    \"Cybersecurity for critical systems\": 14,\n",
    "    \"Regulating big tech companies\": 11,\n",
    "    \"Modernizing the power grid\": 17,\n",
    "    \"Funding for scientific research (NIH, NSF)\": 9,\n",
    "    # Government Reform & Ethics\n",
    "    \"Campaign finance reform\": 20,\n",
    "    \"Addressing political corruption\": 13,\n",
    "    \"Term limits for elected officials\": 8,\n",
    "    \"Protecting whistleblowers\": 6,\n",
    "    \"Strengthening ethics regulations\": 10,\n",
    "    # Economy & Labor (Different Focus)\n",
    "    \"Raising the federal minimum wage\": 24,\n",
    "    \"Supporting small business recovery\": 21,\n",
    "    \"Protecting workers' right to organize\": 18,\n",
    "    \"Addressing income inequality\": 20,\n",
    "    \"Investing in workforce development programs\": 15,\n",
    "    # Agriculture & Environment (Different Focus)\n",
    "    \"Supporting sustainable farming practices\": 7,\n",
    "    \"Ensuring food safety and security\": 11,\n",
    "    \"Protecting national parks and public lands\": 19,\n",
    "    \"Water resource management\": 14,\n",
    "    # Other\n",
    "    \"Addressing the opioid crisis\": 22,\n",
    "    \"Improving veterans' healthcare and benefits\": 27,\n",
    "    \"Affordable housing and homelessness\": 16,\n",
    "    \"Disaster preparedness and relief funding\": 10,\n",
    "}\n",
    "\n",
    "# Sort the topics by frequency in descending order\n",
    "sorted_topics = sorted(topics_to_unify.items(), key=lambda x: x[1], reverse=True)\n",
    "# Format the sorted topics into the required input format\n",
    "input_markdown = \"\\n\".join([f\"- {topic} | {freq}\" for topic, freq in sorted_topics])\n",
    "print(input_markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe970012",
   "metadata": {},
   "source": [
    "## Define the output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedTopic(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a high-level policy category with its constituent original topics.\n",
    "    Ensures each unified topic contains at least two original topics.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(\n",
    "        description=\"Concise name for the unified policy category (1-5 words)\",\n",
    "    )\n",
    "\n",
    "    original_topics: list[str] = Field(\n",
    "        description=\"List of original input topics mapped to this unified category\",\n",
    "    )\n",
    "\n",
    "\n",
    "class UnifiedTopicsOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for political topic unification output with nested topic structure.\n",
    "    Ensures mutual exclusivity through explicit grouping in separate unified topics.\n",
    "    \"\"\"\n",
    "\n",
    "    unified_topics: list[UnifiedTopic] = Field(\n",
    "        description=\"List of high-level policy categories with their constituent original topics. \"\n",
    "        \"Each unified topic must contain at least two original topics, and all original \"\n",
    "        \"topics from input must be included across the list. Categories must be mutually exclusive.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_mapping_from_unified_topics(\n",
    "    unified_topics: UnifiedTopicsOutput,\n",
    ") -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Converts the unified topics output into a mapping of unified topic names to their original topics.\n",
    "\n",
    "    Args:\n",
    "        unified_topics (UnifiedTopicsOutput): The unified topics output.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: A dictionary mapping each unified topic name to its original topics.\n",
    "    \"\"\"\n",
    "    return {ut.name: ut.original_topics for ut in unified_topics.unified_topics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b51150",
   "metadata": {},
   "source": [
    "## Test different LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the outputs of each method in a dictionary (key = method name)\n",
    "topics_unification_results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546428b",
   "metadata": {},
   "source": [
    "### Initialize the LLM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=settings.openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494e588",
   "metadata": {},
   "source": [
    "### GPT 4.1 nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ebc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"gpt-4.1-nano-2025-04-14\"\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=llm_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input_markdown,\n",
    "        },\n",
    "    ],\n",
    "    response_format=UnifiedTopicsOutput,  # Specify the schema for the structured output\n",
    "    temperature=0,  # Low temperature should lead to less hallucination\n",
    "    seed=42,  # Fix the seed for reproducibility\n",
    ")\n",
    "topics_unification_results[llm_name] = completion.choices[0].message.parsed\n",
    "assert isinstance(topics_unification_results[llm_name], UnifiedTopicsOutput), (\n",
    "    \"Output does not match the expected schema.\"\n",
    ")\n",
    "topics_unification_results[llm_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b50640",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_topic_names = [\n",
    "    topic.name for topic in topics_unification_results[llm_name].unified_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} generated {len(unified_topic_names)} unified topics: {', '.join(unified_topic_names)}\"\n",
    ")\n",
    "topic_word_lengths = [\n",
    "    len(topic.name.split())\n",
    "    for topic in topics_unification_results[llm_name].unified_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} generated unified topics with average word length of {sum(topic_word_lengths) / len(topic_word_lengths):.2f}\"\n",
    ")\n",
    "mapped_topics = [\n",
    "    original_topic\n",
    "    for unified_topic in topics_unification_results[llm_name].unified_topics\n",
    "    for original_topic in unified_topic.original_topics\n",
    "]\n",
    "unmapped_topics = [\n",
    "    topic for topic in topics_to_unify.keys() if topic not in mapped_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} left {len(unmapped_topics)} unmapped topics: {', '.join(unmapped_topics)}\"\n",
    ")\n",
    "hallucinated_topics = [\n",
    "    topic for topic in mapped_topics if topic not in topics_to_unify.keys()\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} hallucinated {len(hallucinated_topics)} topics: {', '.join(hallucinated_topics)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = get_topic_mapping_from_unified_topics(\n",
    "    unified_topics=topics_unification_results[llm_name]\n",
    ")\n",
    "mapped_topics = {\n",
    "    input_topic: map_topic(input_topic, topic_mapping)\n",
    "    for input_topic in topics_to_unify.keys()\n",
    "}\n",
    "mapped_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59adc6",
   "metadata": {},
   "source": [
    "GPT 4.1 nano can sometimes hallucinate topics. It also often leaves input topics unmapped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492f34b",
   "metadata": {},
   "source": [
    "### GPT 4.1 mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a4addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"gpt-4.1-mini-2025-04-14\"\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=llm_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input_markdown,\n",
    "        },\n",
    "    ],\n",
    "    response_format=UnifiedTopicsOutput,  # Specify the schema for the structured output\n",
    "    temperature=0,  # Low temperature should lead to less hallucination\n",
    "    seed=42,  # Fix the seed for reproducibility\n",
    ")\n",
    "topics_unification_results[llm_name] = completion.choices[0].message.parsed\n",
    "assert isinstance(topics_unification_results[llm_name], UnifiedTopicsOutput), (\n",
    "    \"Output does not match the expected schema.\"\n",
    ")\n",
    "topics_unification_results[llm_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_topic_names = [\n",
    "    topic.name for topic in topics_unification_results[llm_name].unified_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} generated {len(unified_topic_names)} unified topics: {', '.join(unified_topic_names)}\"\n",
    ")\n",
    "topic_word_lengths = [\n",
    "    len(topic.name.split())\n",
    "    for topic in topics_unification_results[llm_name].unified_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} generated unified topics with average word length of {sum(topic_word_lengths) / len(topic_word_lengths):.2f}\"\n",
    ")\n",
    "mapped_topics = [\n",
    "    original_topic\n",
    "    for unified_topic in topics_unification_results[llm_name].unified_topics\n",
    "    for original_topic in unified_topic.original_topics\n",
    "]\n",
    "unmapped_topics = [\n",
    "    topic for topic in topics_to_unify.keys() if topic not in mapped_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} left {len(unmapped_topics)} unmapped topics: {', '.join(unmapped_topics)}\"\n",
    ")\n",
    "hallucinated_topics = [\n",
    "    topic for topic in mapped_topics if topic not in topics_to_unify.keys()\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} hallucinated {len(hallucinated_topics)} topics: {', '.join(hallucinated_topics)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c41cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = get_topic_mapping_from_unified_topics(\n",
    "    unified_topics=topics_unification_results[llm_name]\n",
    ")\n",
    "mapped_topics = {\n",
    "    input_topic: map_topic(input_topic, topic_mapping)\n",
    "    for input_topic in topics_to_unify.keys()\n",
    "}\n",
    "mapped_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db01a57",
   "metadata": {},
   "source": [
    "GPT 4.1 mini can leave some input topics unmapped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51acf11",
   "metadata": {},
   "source": [
    "### GPT 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"gpt-4.1-2025-04-14\"\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=llm_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input_markdown,\n",
    "        },\n",
    "    ],\n",
    "    response_format=UnifiedTopicsOutput,  # Specify the schema for the structured output\n",
    "    temperature=0,  # Low temperature should lead to less hallucination\n",
    "    seed=42,  # Fix the seed for reproducibility\n",
    ")\n",
    "topics_unification_results[llm_name] = completion.choices[0].message.parsed\n",
    "assert isinstance(topics_unification_results[llm_name], UnifiedTopicsOutput), (\n",
    "    \"Output does not match the expected schema.\"\n",
    ")\n",
    "topics_unification_results[llm_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a991e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_topic_names = [\n",
    "    topic.name for topic in topics_unification_results[llm_name].unified_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} generated {len(unified_topic_names)} unified topics: {', '.join(unified_topic_names)}\"\n",
    ")\n",
    "topic_word_lengths = [\n",
    "    len(topic.name.split())\n",
    "    for topic in topics_unification_results[llm_name].unified_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} generated unified topics with average word length of {sum(topic_word_lengths) / len(topic_word_lengths):.2f}\"\n",
    ")\n",
    "mapped_topics = [\n",
    "    original_topic\n",
    "    for unified_topic in topics_unification_results[llm_name].unified_topics\n",
    "    for original_topic in unified_topic.original_topics\n",
    "]\n",
    "unmapped_topics = [\n",
    "    topic for topic in topics_to_unify.keys() if topic not in mapped_topics\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} left {len(unmapped_topics)} unmapped topics: {', '.join(unmapped_topics)}\"\n",
    ")\n",
    "hallucinated_topics = [\n",
    "    topic for topic in mapped_topics if topic not in topics_to_unify.keys()\n",
    "]\n",
    "print(\n",
    "    f\"{llm_name} hallucinated {len(hallucinated_topics)} topics: {', '.join(hallucinated_topics)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ea14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = get_topic_mapping_from_unified_topics(\n",
    "    unified_topics=topics_unification_results[llm_name]\n",
    ")\n",
    "mapped_topics = {\n",
    "    input_topic: map_topic(input_topic, topic_mapping)\n",
    "    for input_topic in topics_to_unify.keys()\n",
    "}\n",
    "mapped_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a3ee0",
   "metadata": {},
   "source": [
    "GPT 4.1 seems pretty reliable in following the instructions. No sign of hallucinated nor unmapped topics. It also consistently generates a shorter list of unified topics, with each one being more concisely worded than the smaller LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f5026",
   "metadata": {},
   "source": [
    "### Implemented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ef9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_unifier = OpenAITopicUnifier()\n",
    "topics_unification_results_polids = topic_unifier.process(\n",
    "    input_topic_frequencies=topics_to_unify\n",
    ")\n",
    "topics_unification_results_polids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab53ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_topics = {\n",
    "    input_topic: topic_unifier.map_input_topic_to_unified_topic(input_topic)\n",
    "    for input_topic in topics_to_unify.keys()\n",
    "}\n",
    "mapped_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f6d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
