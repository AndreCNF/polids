{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word cloud\n",
    "---\n",
    "\n",
    "Experiment with generating a word cloud from text. It should include a cleanup of the text, excluding stop words and punctuation, as well as setting everything in lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "from lingua import LanguageDetectorBuilder\n",
    "import pycountry\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import simplemma\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polids.word_cloud.wordcloud import WordCloudGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_data_path = Path(\"data/portugal_2022/programs/\")\n",
    "# Using this PDF which had issues with stopwords before (e.g. a lot of \"se\")\n",
    "human_annotated_md = human_annotated_data_path / \"be.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = human_annotated_md.read_text()\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include only languages that are not yet extinct (= currently excludes Latin)\n",
    "language_detector = LanguageDetectorBuilder.from_all_spoken_languages().build()\n",
    "language_detection_result = language_detector.detect_language_of(markdown_content)\n",
    "detected_language = language_detection_result.name.lower()\n",
    "print(f\"Detected language: {detected_language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_language_code = pycountry.languages.get(\n",
    "    name=detected_language.capitalize()\n",
    ").alpha_2\n",
    "print(f\"Detected language code: {detected_language_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(detected_language))\n",
    "print(f\"Stop words in {detected_language}:\\n{', '.join(stop_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(markdown_content)\n",
    "# Lowercase and trim words\n",
    "word_tokens_clean = [w.lower().strip() for w in word_tokens]\n",
    "# Filter and clean words\n",
    "filtered_words = [\n",
    "    # Convert to lower case and lemmatize the words\n",
    "    simplemma.lemmatize(w.lower(), lang=detected_language_code)\n",
    "    for w in word_tokens_clean\n",
    "    # Remove stopwords\n",
    "    if w.lower() not in stop_words\n",
    "    # Remove punctuation and markdown symbols\n",
    "    and w not in string.punctuation\n",
    "    and not w.startswith(\"#\")\n",
    "    # Remove words with numbers\n",
    "    and not any(char.isdigit() for char in w)\n",
    "]\n",
    "# Stem words if they have a special character\n",
    "stemmer = SnowballStemmer(detected_language)\n",
    "filtered_words = [\n",
    "    stemmer.stem(w) if any(char in string.punctuation for char in w) else w\n",
    "    for w in filtered_words\n",
    "]\n",
    "# Remove words with less than 3 characters\n",
    "filtered_words = [w for w in filtered_words if len(w) > 2]\n",
    "print(f\"Filtered words:\\n{', '.join(filtered_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_cloud(\n",
    "    words: list[str],\n",
    "    max_words: int = 500,\n",
    "    image_path: str | None = None,\n",
    "    image_name: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a word cloud based on a set of words.\n",
    "\n",
    "    Args:\n",
    "        words (list[str]):\n",
    "            List of words to be included in the word cloud.\n",
    "        max_words (int):\n",
    "            Maximum number of words to be included in the word cloud.\n",
    "        image_path (str):\n",
    "            Path to the image file where to save the word cloud.\n",
    "        image_name (str):\n",
    "            Name of the image where to save the word cloud.\n",
    "    \"\"\"\n",
    "\n",
    "    # Change the value to black\n",
    "    def black_color_func(\n",
    "        word, font_size, position, orientation, random_state=None, **kwargs\n",
    "    ):\n",
    "        return \"hsl(0,100%, 1%)\"\n",
    "\n",
    "    # Set the wordcloud background color to white\n",
    "    # Set width and height to higher quality, 3000 x 2000\n",
    "    wordcloud = WordCloud(\n",
    "        background_color=\"white\",\n",
    "        width=3000,\n",
    "        height=2000,\n",
    "        max_words=max_words,\n",
    "        stopwords=None,  # We already filtered the stopwords\n",
    "        regexp=None,  # Just split on whitespace\n",
    "        min_word_length=3,  # Drop words with less than 3 characters\n",
    "    ).generate(\" \".join(words))\n",
    "    # Set the word color to black\n",
    "    wordcloud.recolor(color_func=black_color_func)\n",
    "    # Set the figsize\n",
    "    plt.figure(figsize=[15, 10])\n",
    "    # Plot the wordcloud\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    # Remove plot axes\n",
    "    plt.axis(\"off\")\n",
    "    if image_path is not None and image_name is not None:\n",
    "        # Save the image\n",
    "        plt.savefig(os.path.join(image_path, image_name), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_word_cloud(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_generator = WordCloudGenerator(text=markdown_content)\n",
    "word_cloud_generator.generate_word_cloud(image_path=None, image_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
