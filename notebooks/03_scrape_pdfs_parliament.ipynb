{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape PDFs from the Portuguese Parliament\n",
    "---\n",
    "Initial experiments to scrape proposals and voting tables from official PDFs from the Portuguese Parliament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += \":/opt/homebrew/lib:/opt/homebrew/bin/gs\"\n",
    "os.environ[\"DYLD_LIBRARY_PATH\"] = \"/opt/homebrew/lib\"   # this is needed for MacOS to find the Ghostscript library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import camelot\n",
    "from camelot.handlers import PDFHandler\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.output_parsers import ListOutputParser\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from getpass import getpass\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deputies_per_party = {\n",
    "    \"PS\": 120,\n",
    "    \"PSD\": 77,\n",
    "    \"CH\": 12,\n",
    "    \"IL\": 8,\n",
    "    \"PCP\": 6,\n",
    "    \"BE\": 5,\n",
    "    \"PAN\": 1,\n",
    "    \"L\": 1,\n",
    "}\n",
    "gov = \"PS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/Users/adminuser/Downloads/XV_1_151_2023-07-07_ResultadoVotacoes_2023-07-07.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape proposals' text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant_proposal(text: str) -> bool:\n",
    "    \"\"\"Check if a proposal is relevant for our analysis.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text of the proposal.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the proposal is relevant, False otherwise.\n",
    "    \"\"\"\n",
    "    if (\n",
    "        (\n",
    "            all(party in text for party in deputies_per_party.keys()) \n",
    "            or \"GOV\" in text\n",
    "        )\n",
    "        and (\n",
    "            any(word in text.lower() for word in [\"favor\", \"contra\", \"abstenção\"])\n",
    "            or any(word in text for word in [\"aprovad\", \"rejeitad\"])\n",
    "        )\n",
    "    ):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_proposal_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Process the dedescription of a proposal, removing unnecessary text\n",
    "    and symbols.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text of the proposal.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed text of the proposal.\n",
    "    \"\"\"\n",
    "    return text.split(\"Aprovad\")[0].split(\"Rejeitad\")[0].replace(\"\\n\", \"\").replace(\"  \", \" \").replace(\";\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[2].page_content.split(\"\\uf0de\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[text for text in pages[2].page_content.split(\"\\uf0de\")[1:] if is_relevant_proposal(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[clean_proposal_text(text) for text in pages[2].page_content.split(\"\\uf0de\")[1:] if is_relevant_proposal(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = list()\n",
    "unanimous_idx = list()\n",
    "for page in pages:\n",
    "    page_proposals = [text for text in page.page_content.split(\"\\uf0de\")[1:]] #if is_relevant_proposal(text)]\n",
    "    for idx, prop in enumerate(page_proposals):\n",
    "        if \"unanimidade\" in prop.lower():\n",
    "            unanimous_idx.append(len(proposals) + idx)\n",
    "    proposals.extend(page_proposals) #[clean_proposal_text(text) for text in page_proposals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanimous_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proposals) - len(unanimous_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape voting tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_mid_coords(bbox: Tuple[float, float, float, float], offset: int = 10) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Get the coordinates of the middle of the top of a bounding box.\n",
    "\n",
    "    Args:\n",
    "        bbox (Tuple[float, float, float, float]): The bounding box.\n",
    "        offset (int, optional): The offset to add to the y coordinate. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The coordinates of the middle of the top of the bounding box.\n",
    "    \"\"\"\n",
    "    return ((bbox[0] + bbox[2]) / 2, bbox[3] + offset)\n",
    "\n",
    "def get_bottom_mid(bbox):\n",
    "    \"\"\"\n",
    "    Get the coordinates of the middle of the bottom of a bounding box.\n",
    "\n",
    "    Args:\n",
    "        bbox (Tuple[float, float, float, float]): The bounding box.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[float, float]: The coordinates of the middle of the bottom of the bounding box.\n",
    "    \"\"\"\n",
    "    return ((bbox[0] + bbox[2]) / 2, bbox[1])\n",
    "\n",
    "def calc_distance_between_coords(p1: Tuple[float, float], p2: Tuple[float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the distance between two points.\n",
    "\n",
    "    Args:\n",
    "        p1 (Tuple[float, float]): The first point.\n",
    "        p2 (Tuple[float, float]): The second point.\n",
    "\n",
    "    Returns:\n",
    "        float: The distance between the two points.\n",
    "    \"\"\"\n",
    "    return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n",
    "\n",
    "def get_closest_text(table, htext_objs, initial_offset: int = 0, max_tries: int = 100):\n",
    "    best_guess = None\n",
    "    best_guess_length = 0\n",
    "    offset = initial_offset\n",
    "    num_tries = 0\n",
    "    while (best_guess_length < 10) and (num_tries < max_tries):\n",
    "        min_distance = np.inf\n",
    "        table_mid = get_top_mid_coords(table._bbox, offset=offset)  # middle of the TOP of the table\n",
    "        for obj in htext_objs:\n",
    "            text_mid = get_bottom_mid(obj.bbox)  # middle of the BOTTOM of the text\n",
    "            d = calc_distance_between_coords(text_mid, table_mid)\n",
    "            if d < min_distance:\n",
    "                best_guess = obj.get_text().strip()\n",
    "                min_distance = d\n",
    "                best_guess_length = len(best_guess)\n",
    "        offset += 1\n",
    "        num_tries += 1\n",
    "    return best_guess\n",
    "\n",
    "def get_tables_and_titles(pdf_filename):\n",
    "    \"\"\"Here's my hacky code for grabbing tables and guessing at their titles\"\"\"\n",
    "    my_handler = PDFHandler(pdf_filename)  # from camelot.handlers import PDFHandler\n",
    "    tables = camelot.read_pdf(pdf_filename, pages=\"all\")\n",
    "    titles = []\n",
    "    with camelot.utils.TemporaryDirectory() as tempdir:\n",
    "        for table in tqdm(tables, desc=f\"Extracting {tables.n:d} tables\"):\n",
    "            my_handler._save_page(pdf_filename, table.page, tempdir)\n",
    "            tmp_file_path = os.path.join(tempdir, f'page-{table.page}.pdf')\n",
    "            layout, dim = camelot.utils.get_page_layout(tmp_file_path)\n",
    "            htext_objs = camelot.utils.get_text_objects(layout, ltype=\"horizontal_text\")\n",
    "            titles.append(get_closest_text(table, htext_objs))  # Might be None\n",
    "\n",
    "    return titles, tables\n",
    "\n",
    "titles, tables = get_tables_and_titles(pdf_path)\n",
    "for title, table in zip(titles, tables):\n",
    "    print(title)\n",
    "    display(table.df)\n",
    "    print(\"---------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate a table for each proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_idx_of_proposal = {idx: None for idx in range(len(proposals))}\n",
    "tables_to_be_assigned = [idx for idx in range(len(tables)) if len(titles[idx]) > 0]\n",
    "for proposal_idx, proposal_text in enumerate(proposals):\n",
    "    if proposal_idx in unanimous_idx:\n",
    "        table_idx_of_proposal[proposal_idx] = -1\n",
    "        continue\n",
    "    table_idx = tables_to_be_assigned[0]\n",
    "    if len(titles[table_idx]) > 0 and titles[table_idx].lower().replace(\"\\uf0de\", \"\").replace(\" \", \"\") in proposal_text.lower().replace(\"\\uf0de\", \"\").replace(\" \", \"\"):\n",
    "        table_idx_of_proposal[proposal_idx] = table_idx\n",
    "        tables_to_be_assigned.remove(table_idx)\n",
    "        continue\n",
    "tables_to_be_assigned += [idx for idx in range(len(tables)) if len(titles[idx]) == 0]\n",
    "print(\n",
    "    f\"Tables left to be assigned: {len(tables_to_be_assigned)}\\n\"\n",
    "    f\"Proposals left to be assigned: {len([idx for idx, table_idx in table_idx_of_proposal.items() if table_idx is None])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_without_table = [\n",
    "    proposals[idx]\n",
    "    for idx in range(len(proposals))\n",
    "    if table_idx_of_proposal[idx] is None\n",
    "]\n",
    "proposals_without_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_without_owner_party = [\n",
    "    proposal\n",
    "    for proposal in proposals\n",
    "    if not (\n",
    "        any(f\"({party})\" in proposal.replace(\" \", \"\") for party in deputies_per_party.keys()) \n",
    "        or \"(GOV)\" in proposal.replace(\" \", \"\")\n",
    "    )\n",
    "]\n",
    "proposals_without_owner_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proposal in proposals_without_owner_party:\n",
    "    idx = proposals.index(proposal)\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    if (table_idx_of_proposal[idx-1] is None) and (table_idx_of_proposal[idx] is not None):\n",
    "        table_idx_of_proposal[idx-1] = table_idx_of_proposal[idx]\n",
    "        proposals_without_table.remove(proposals[idx-1])\n",
    "        proposals.remove(proposal)\n",
    "        # shift all the indices of table_idx_of_proposal\n",
    "        for i in range(idx, len(table_idx_of_proposal)-1):\n",
    "            table_idx_of_proposal[i] = table_idx_of_proposal[i+1]\n",
    "        table_idx_of_proposal.pop(list(table_idx_of_proposal.keys())[-1])\n",
    "print(\n",
    "    f\"Tables left to be assigned: {len(tables_to_be_assigned)}\\n\"\n",
    "    f\"Proposals left to be assigned: {len(proposals_without_table)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(proposals_without_table) == len(tables_to_be_assigned):\n",
    "    pairs_to_assign = list(zip(proposals_without_table, tables_to_be_assigned))\n",
    "    for proposal, table_idx in pairs_to_assign:\n",
    "        proposal_idx = proposals.index(proposal)\n",
    "        # only assign this table if it occurs between two nearest proposals' tables\n",
    "        previous_table_idx = max(\n",
    "            [\n",
    "                table_idx_of_proposal[idx]\n",
    "                for idx in range(proposal_idx)\n",
    "                if table_idx_of_proposal[idx] is not None\n",
    "            ]\n",
    "        )\n",
    "        next_table_idx = min(\n",
    "            [\n",
    "                table_idx_of_proposal[idx]\n",
    "                for idx in range(proposal_idx, len(proposals))\n",
    "                if table_idx_of_proposal[idx] is not None\n",
    "                and table_idx_of_proposal[idx] != -1\n",
    "            ]\n",
    "        )\n",
    "        if table_idx > previous_table_idx and table_idx < next_table_idx:\n",
    "            table_idx_of_proposal[proposal_idx] = table_idx\n",
    "            proposals_without_table.remove(proposal)\n",
    "            tables_to_be_assigned.remove(table_idx)\n",
    "print(\n",
    "    f\"Tables left to be assigned: {len(tables_to_be_assigned)}\\n\"\n",
    "    f\"Proposals left to be assigned: {len(proposals_without_table)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_idx_of_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table for unanimous votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unanimous_df = pd.DataFrame(\n",
    "    {\n",
    "        \"voto\": [\"FAVOR\", \"CONTRA\", \"ABSTENÇÃO\"],\n",
    "    } | {\n",
    "        party: [num_deputies, 0, 0]\n",
    "        for party, num_deputies in deputies_per_party.items()\n",
    "    },\n",
    "    index=[0, 1, 2],\n",
    ")\n",
    "unanimous_df.set_index(\"voto\", inplace=True)\n",
    "unanimous_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tables into rows and merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_voting_table(voting_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans up the voting table, fixing the header and making data numeric.\n",
    "\n",
    "    Args:\n",
    "        voting_df (pd.DataFrame): The voting table to be cleaned up.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned up voting table.\n",
    "    \"\"\"\n",
    "    # fix the header\n",
    "    voting_df = voting_df.loc[1:, :]\n",
    "    voting_df.columns = [\"voto\"] + list(unanimous_df.columns)\n",
    "    # make data numeric\n",
    "    for party, num_deputies in deputies_per_party.items():\n",
    "        voting_df[party] = voting_df[party].replace(\"X\", num_deputies).replace(\"\", 0).astype(int)\n",
    "    # set the index\n",
    "    voting_df.set_index(\"voto\", inplace=True)\n",
    "    return voting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[1].df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_voting_table(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"CONTRA\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"CONTRA\"].sum() / df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PS\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" | \".join([party for party in deputies_per_party.keys() if f\"({party})\" in proposal.replace(\" \", \"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()\n",
    "party_decisions = {party: list() for party in deputies_per_party.keys()}\n",
    "descriptions = list()\n",
    "owners = list()\n",
    "for proposal_idx, table_idx in table_idx_of_proposal.items():\n",
    "    if table_idx == None:\n",
    "        continue\n",
    "    elif table_idx == -1:\n",
    "        table_df = unanimous_df\n",
    "    else:\n",
    "        table_df = tables[table_idx].df\n",
    "        table_df = clean_voting_table(table_df)\n",
    "    results.append(\n",
    "        \"aprovada\"\n",
    "        if table_df.loc[\"CONTRA\"].sum() / table_df.sum().sum() < 0.5\n",
    "        else \"rejeitada\"\n",
    "    )\n",
    "    for party in party_decisions.keys():\n",
    "        party_majority_vote = table_df[party].idxmax()\n",
    "        if party_majority_vote == \"FAVOR\":\n",
    "            party_decisions[party].append(\"favor\")\n",
    "        elif party_majority_vote == \"CONTRA\":\n",
    "            party_decisions[party].append(\"contra\")\n",
    "        else:\n",
    "            party_decisions[party].append(\"abstenção\")\n",
    "    descriptions.append(proposals[proposal_idx])\n",
    "    owners.append(\n",
    "        \" | \".join(\n",
    "            [\n",
    "                party\n",
    "                for party in deputies_per_party.keys()\n",
    "                if f\"({party})\" in proposals[proposal_idx].replace(\" \", \"\").replace(\"(GOV)\", f\"({gov})\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "final_df = pd.DataFrame(\n",
    "    {\n",
    "        \"resultado\": results,\n",
    "        **party_decisions,\n",
    "        \"descricao\": descriptions,\n",
    "        \"proposta_por\": owners,\n",
    "    }\n",
    ")\n",
    "final_df.descricao = final_df.descricao.apply(clean_proposal_text)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleaning of proposals' text with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(final_df.descricao.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewLineOutputParser(ListOutputParser):\n",
    "    @property\n",
    "    def lc_serializable(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return (\n",
    "            \"Your response should be a list of new line separated values, \"\n",
    "            \"eg: `foo\\nbar\\nbaz`\"\n",
    "        )\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful Portuguese writer, with experience in editing articles in Portuguese and correcting typos.\"\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"Corrige o texto seguinte, removendo e criando espaços para formar palavras em Português corretamente:\\n{text}\"\n",
    ")\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_prompt,\n",
    "        human_message_prompt,\n",
    "    ]\n",
    ")\n",
    "output_parser = NewLineOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = list(final_df.descricao.values)\n",
    "outputs = list()\n",
    "for i in tqdm(range(0, len(descriptions), 10)):\n",
    "    input_prompt = chat_prompt.format_messages(text=descriptions[i : i + 10], format_instructions=output_parser.get_format_instructions())\n",
    "    output = llm(input_prompt)\n",
    "    output_parsed = output_parser.parse(output.content)\n",
    "    outputs.extend(output_parsed)\n",
    "outputs = [output for output in outputs if len(output) > 0]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs), len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Descriptions before chatbot:\\n{final_df.descricao.values[:5]}\\n\")\n",
    "final_df.descricao = outputs\n",
    "print(f\"Descriptions after chatbot:\\n{final_df.descricao.values[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polids-GqBxlbqG-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
