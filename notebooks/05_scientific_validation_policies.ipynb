{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a038bd6",
   "metadata": {},
   "source": [
    "# Scientific validation of policy proposals\n",
    "---\n",
    "Experimenting with web search APIs for scientific validation of policy proposals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f82055",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68012ac",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dbf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from tqdm.auto import tqdm\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polids.config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e316f2c6",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc968457",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Search the web for credible scientific context related to a given policy proposal, and determine its scientific validation.\n",
    "\n",
    "Identify and evaluate sources such as highly cited academic papers, randomized controlled trials (RCTs), and reputable news outlets with scientific grounding. Based on this research, provide a validation outcome and a justification.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Identify Keywords**: Extract main concepts and terms from the policy proposal to guide your search.\n",
    "2. **Conduct Web Search**: Use the identified keywords to search for scientific literature, credible reports, and analyses related to the policy.\n",
    "3. **Evaluate Sources**: Prioritize sources based on credibility, relevance, and citation count. Look for consensus among multiple credible sources to enhance reliability.\n",
    "4. **Synthesize Information**: Summarize the findings clearly indicating whether the scientific evidence supports or refutes the proposal.\n",
    "5. **Conclude Validation**: Determine if the policy is scientifically validated based on gathered evidence.\n",
    "6. **Provide Reasoning**: Articulate the reasoning based on the findings, citing key evidence.\n",
    "\n",
    "# Notes\n",
    "\n",
    "- Regardless of the original language of the proposal, the search should be conducted in English and the results should be presented in English.\n",
    "- Ensure the evaluation is grounded in current and credible scientific data.\n",
    "- Consider the strength and consensus of evidence rather than anecdotal or single-study claims.\n",
    "- If evidence is mixed, provide a balanced view in the reasoning string.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380113cc",
   "metadata": {},
   "source": [
    "## Load policies to validate\n",
    "We're going to start from manually defined policies, so as to avoid dependencies on previous steps of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed47a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "policies_to_validate = {\n",
    "    \"carbon_tax\": \"Implementing a carbon tax to reduce greenhouse gas emissions.\",\n",
    "    \"vaccines\": \"Mandatory vaccination for all school-aged children to prevent outbreaks of infectious diseases.\",\n",
    "    \"ubi\": \"Implementing universal basic income to address income inequality and support job displacement due to automation.\",\n",
    "    \"immigration_jobs\": \"Reducing immigration quotas to improve job opportunities for native citizens.\",\n",
    "    \"immigration_crime\": \"Blocking immigration from countries with different cultural backgrounds to reduce crime rates.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe970012",
   "metadata": {},
   "source": [
    "## Define the output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScientificValidation(BaseModel):\n",
    "    is_validated: bool = Field(\n",
    "        description=\"Indicates whether the policy proposal is scientifically validated or not.\"\n",
    "    )\n",
    "    is_validation_consensual_and_reliable: bool = Field(\n",
    "        description=\"Indicates whether the validation is based on a consensus of multiple reliable sources.\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"A detailed explanation of the validation outcome, including key evidence and sources.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b51150",
   "metadata": {},
   "source": [
    "## Test different search APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546428b",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=settings.openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494e588",
   "metadata": {},
   "source": [
    "#### GPT 4o mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006d7e7",
   "metadata": {},
   "source": [
    "##### Low search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b81f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_validation_results = {\n",
    "    example_name: None for example_name in policies_to_validate.keys()\n",
    "}\n",
    "citations = {example_name: None for example_name in policies_to_validate.keys()}\n",
    "for example_name, example_policy in tqdm(policies_to_validate.items()):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini-search-preview\",\n",
    "        web_search_options={\n",
    "            \"search_context_size\": \"low\",\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example_policy,\n",
    "            },\n",
    "        ],\n",
    "        response_format=ScientificValidation,  # Specify the schema for the structured output\n",
    "    )\n",
    "    policy_validation_results[example_name] = completion.choices[0].message.parsed\n",
    "    assert isinstance(policy_validation_results[example_name], ScientificValidation), (\n",
    "        \"Output does not match the expected schema.\"\n",
    "    )\n",
    "    citations[example_name] = completion.choices[0].message.annotations\n",
    "policy_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ae459",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef6108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the reasoning, in an easier to read format\n",
    "display(Markdown(policy_validation_results[example_name].reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbd04a",
   "metadata": {},
   "source": [
    "Seems like GPT 4o mini with low search often doesn't use any search results at all. When it does, I'm only seeing two citations. This is not enough to validate a policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c150b0",
   "metadata": {},
   "source": [
    "##### Medium search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fe4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_validation_results = {\n",
    "    example_name: None for example_name in policies_to_validate.keys()\n",
    "}\n",
    "citations = {example_name: None for example_name in policies_to_validate.keys()}\n",
    "for example_name, example_policy in tqdm(policies_to_validate.items()):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini-search-preview\",\n",
    "        web_search_options={\n",
    "            \"search_context_size\": \"medium\",\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example_policy,\n",
    "            },\n",
    "        ],\n",
    "        response_format=ScientificValidation,  # Specify the schema for the structured output\n",
    "    )\n",
    "    policy_validation_results[example_name] = completion.choices[0].message.parsed\n",
    "    assert isinstance(policy_validation_results[example_name], ScientificValidation), (\n",
    "        \"Output does not match the expected schema.\"\n",
    "    )\n",
    "    citations[example_name] = completion.choices[0].message.annotations\n",
    "policy_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the reasoning, in an easier to read format\n",
    "display(Markdown(policy_validation_results[example_name].reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7f3b8",
   "metadata": {},
   "source": [
    "##### High search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf02692",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_validation_results = {\n",
    "    example_name: None for example_name in policies_to_validate.keys()\n",
    "}\n",
    "citations = {example_name: None for example_name in policies_to_validate.keys()}\n",
    "for example_name, example_policy in tqdm(policies_to_validate.items()):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini-search-preview\",\n",
    "        web_search_options={\n",
    "            \"search_context_size\": \"high\",\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example_policy,\n",
    "            },\n",
    "        ],\n",
    "        response_format=ScientificValidation,  # Specify the schema for the structured output\n",
    "    )\n",
    "    policy_validation_results[example_name] = completion.choices[0].message.parsed\n",
    "    assert isinstance(policy_validation_results[example_name], ScientificValidation), (\n",
    "        \"Output does not match the expected schema.\"\n",
    "    )\n",
    "    citations[example_name] = completion.choices[0].message.annotations\n",
    "policy_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b895b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the reasoning, in an easier to read format\n",
    "display(Markdown(policy_validation_results[example_name].reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45265eb4",
   "metadata": {},
   "source": [
    "#### GPT 4o (larger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d5f76",
   "metadata": {},
   "source": [
    "##### Low search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_validation_results = {\n",
    "    example_name: None for example_name in policies_to_validate.keys()\n",
    "}\n",
    "citations = {example_name: None for example_name in policies_to_validate.keys()}\n",
    "for example_name, example_policy in tqdm(policies_to_validate.items()):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-search-preview\",\n",
    "        web_search_options={\n",
    "            \"search_context_size\": \"low\",\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example_policy,\n",
    "            },\n",
    "        ],\n",
    "        response_format=ScientificValidation,  # Specify the schema for the structured output\n",
    "    )\n",
    "    policy_validation_results[example_name] = completion.choices[0].message.parsed\n",
    "    assert isinstance(policy_validation_results[example_name], ScientificValidation), (\n",
    "        \"Output does not match the expected schema.\"\n",
    "    )\n",
    "    citations[example_name] = completion.choices[0].message.annotations\n",
    "policy_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d72ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the reasoning, in an easier to read format\n",
    "display(Markdown(policy_validation_results[example_name].reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820dd8fa",
   "metadata": {},
   "source": [
    "##### Medium search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_validation_results = {\n",
    "    example_name: None for example_name in policies_to_validate.keys()\n",
    "}\n",
    "citations = {example_name: None for example_name in policies_to_validate.keys()}\n",
    "for example_name, example_policy in tqdm(policies_to_validate.items()):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-search-preview\",\n",
    "        web_search_options={\n",
    "            \"search_context_size\": \"medium\",\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example_policy,\n",
    "            },\n",
    "        ],\n",
    "        response_format=ScientificValidation,  # Specify the schema for the structured output\n",
    "    )\n",
    "    policy_validation_results[example_name] = completion.choices[0].message.parsed\n",
    "    assert isinstance(policy_validation_results[example_name], ScientificValidation), (\n",
    "        \"Output does not match the expected schema.\"\n",
    "    )\n",
    "    citations[example_name] = completion.choices[0].message.annotations\n",
    "policy_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90368961",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the reasoning, in an easier to read format\n",
    "display(Markdown(policy_validation_results[example_name].reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c86123",
   "metadata": {},
   "source": [
    "##### High search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_validation_results = {\n",
    "    example_name: None for example_name in policies_to_validate.keys()\n",
    "}\n",
    "citations = {example_name: None for example_name in policies_to_validate.keys()}\n",
    "for example_name, example_policy in tqdm(policies_to_validate.items()):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-search-preview\",\n",
    "        web_search_options={\n",
    "            \"search_context_size\": \"high\",\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example_policy,\n",
    "            },\n",
    "        ],\n",
    "        response_format=ScientificValidation,  # Specify the schema for the structured output\n",
    "    )\n",
    "    policy_validation_results[example_name] = completion.choices[0].message.parsed\n",
    "    assert isinstance(policy_validation_results[example_name], ScientificValidation), (\n",
    "        \"Output does not match the expected schema.\"\n",
    "    )\n",
    "    citations[example_name] = completion.choices[0].message.annotations\n",
    "policy_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the reasoning, in an easier to read format\n",
    "display(Markdown(policy_validation_results[example_name].reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027885c",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614c0ad",
   "metadata": {},
   "source": [
    "#### Sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328b30d",
   "metadata": {},
   "source": [
    "##### Low search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f81589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6046c589",
   "metadata": {},
   "source": [
    "##### Medium search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189feb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dde98af",
   "metadata": {},
   "source": [
    "##### High search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f86220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c298c4",
   "metadata": {},
   "source": [
    "#### Sonar Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b971a87",
   "metadata": {},
   "source": [
    "##### Low search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae75b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95ec9845",
   "metadata": {},
   "source": [
    "##### Medium search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0edb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1dc4a85",
   "metadata": {},
   "source": [
    "##### High search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc3850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8278dbc",
   "metadata": {},
   "source": [
    "#### Sonar Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaf971",
   "metadata": {},
   "source": [
    "##### Low search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f4062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b51e5e80",
   "metadata": {},
   "source": [
    "##### Medium search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059a8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b1caed7",
   "metadata": {},
   "source": [
    "##### High search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ad28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa041c7d",
   "metadata": {},
   "source": [
    "#### Sonar Reasoning Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666abb97",
   "metadata": {},
   "source": [
    "##### Low search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4464d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "763fd457",
   "metadata": {},
   "source": [
    "##### Medium search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c23dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae91c28",
   "metadata": {},
   "source": [
    "##### High search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6054e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c76112",
   "metadata": {},
   "source": [
    "#### Sonar Deep Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e41f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c97f5026",
   "metadata": {},
   "source": [
    "### Implemented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553e793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
