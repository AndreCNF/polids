{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse PDFs to markdown\n",
    "---\n",
    "\n",
    "Here we'll test parsing some non-English electoral manifestos' PDFs using different approaches. The goal is to extract the text from the PDFs and convert it to markdown, so that it can be easily processed and analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "import requests\n",
    "from pdf2image import convert_from_path\n",
    "from docling.document_converter import DocumentConverter\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "from marker.config.parser import ConfigParser\n",
    "import ollama\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import nest_asyncio\n",
    "import pymupdf4llm\n",
    "from io import BytesIO\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polids.pdf_processing.openai import OpenAIPDFProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_data_path = Path(\"data/elections_portugal/2022/programs_md/\")\n",
    "# small PDF\n",
    "pdf_url = (\n",
    "    \"https://partidolivre.pt/wp-content/uploads/2021/12/Programa_Eleitoral_2022.pdf\"\n",
    ")\n",
    "human_annotated_md = human_annotated_data_path / \"livre.md\"\n",
    "# very large PDF\n",
    "# pdf_urannotated_md = hl = \"https://iniciativaliberal.pt/wp-content/uploads/2022/01/Iniciativa-Liberal-Programa-Eleitoral-2022.pdf\"\n",
    "# human_uman_annotated_data_path / \"liberal.md\"\n",
    "llm_image_parsing_prompt = \"Parse all of the text from this image. Convert it into a markdown format. Only write the content of the image, nothing else\"\n",
    "llm_pdf_parsing_promt = \"Parse all of the text from this PDF. Convert it into a markdown format. Only write the content of the PDF, nothing else\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaParse needs nested async loop to run in a notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = human_annotated_md.read_text()\n",
    "markdown_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the PDF\n",
    "pdf_path = \"downloaded_program.pdf\"\n",
    "response = requests.get(pdf_url)\n",
    "with open(pdf_path, \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = Path(\"tests/data/test_electoral_program.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_parser = OpenAIPDFProcessor()\n",
    "result = pdf_parser.process(pdf_path)\n",
    "display(Markdown(\"\\n\\n---\\n\\n\".join(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this LLM-powered PDF parser is slow, it gives us great output quality at a more reasonable price than other proprietary software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DocumentConverter()\n",
    "result = converter.convert(pdf_url)\n",
    "display(Markdown(result.document.export_to_markdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big issues found:\n",
    "- If the text has columns, it can struggle and merge the text together from separate columns.\n",
    "- Some text that is inside lists is cut from `docling`'s Markdown output. This seems to be an [open issue with the package](https://github.com/docling-project/docling/issues/913)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"use_llm\": True,  # use Gemini 2.0 Flash LLM to improve the output quality\n",
    "    \"gemini_api_key\": os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "    \"paginate_output\": True,  # separate pages in the markdown, using 48x \"-\" separator\n",
    "    \"output_format\": \"markdown\",\n",
    "}\n",
    "config_parser = ConfigParser(config)\n",
    "converter = PdfConverter(\n",
    "    config=config_parser.generate_config_dict(),\n",
    "    artifact_dict=create_model_dict(),\n",
    "    processor_list=config_parser.get_processors(),\n",
    "    renderer=config_parser.get_renderer(),\n",
    "    llm_service=config_parser.get_llm_service(),\n",
    ")\n",
    "rendered = converter(pdf_path)\n",
    "text, _, images = text_from_rendered(rendered)\n",
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better than the `docling` output, with the main cons being:\n",
    "- Slightly longer overhead (some minutes downloading language models);\n",
    "- Adds a newline (`\\n\\n`) when the text in one column switches to the next column on the right.\n",
    "\n",
    "Still, it handles even very large (>600 pages) PDFs well and in under 10 minutes.\n",
    "\n",
    "Adding the LLM usage and paginating the outputs really makes this a great tool for parsing PDFs to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split(48 * \"-\")  # split the text into pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF pages to images\n",
    "pdf_images = convert_from_path(pdf_url, dpi=300)\n",
    "\n",
    "# Save images to files\n",
    "for i, image in enumerate(pdf_images):\n",
    "    image_path = f\"page_{i + 1}.png\"\n",
    "    image.save(image_path, \"PNG\")\n",
    "    print(f\"Saved: {image_path}\")\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ollama.chat(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": llm_image_parsing_prompt,\n",
    "            \"images\": [\"page_2.png\"],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "display(Markdown(res[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ollama.chat(\n",
    "    model=\"gemma3:12b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": llm_image_parsing_prompt,\n",
    "            \"images\": [\"page_2.png\"],\n",
    "        }\n",
    "    ],\n",
    "    options={\"temperature\": 0, \"num_ctx\": 8000},\n",
    ")\n",
    "display(Markdown(res[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Granite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ollama.chat(\n",
    "    model=\"granite3.2-vision\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": llm_image_parsing_prompt,\n",
    "            \"images\": [\"page_2.png\"],\n",
    "        }\n",
    "    ],\n",
    "    options={\"temperature\": 0, \"num_ctx\": 8000},\n",
    ")\n",
    "display(Markdown(res[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ollama.chat(\n",
    "    model=\"llama3.2-vision\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": llm_image_parsing_prompt,\n",
    "            \"images\": [\"page_2.png\"],\n",
    "        }\n",
    "    ],\n",
    "    options={\"temperature\": 0, \"num_ctx\": 8000},\n",
    ")\n",
    "display(Markdown(res[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama 3.2 has EOF issues in Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini\n",
    "\n",
    "I might skip this one for now as it's likely costlier and more expensive than the two options above. If one of the above has good enough outputs then an LLM would be an overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and encode the PDF byte\n",
    "doc_data = httpx.get(pdf_url).content\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-lite-001\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            data=doc_data,\n",
    "            mime_type=\"application/pdf\",\n",
    "        ),\n",
    "        llm_pdf_parsing_promt,\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini 2.0 flash lite can't parse multiple columns correctly. It also seems to cut off instead of going through the entire PDF, albeit this might be solved with changing the max output length or uploading subsets of the pages of the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and encode the PDF byte\n",
    "doc_data = httpx.get(pdf_url).content\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            data=doc_data,\n",
    "            mime_type=\"application/pdf\",\n",
    "        ),\n",
    "        llm_pdf_parsing_promt,\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini 2.0 flash also struggles with multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and encode the PDF byte\n",
    "doc_data = httpx.get(pdf_url).content\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro-exp-03-25\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            data=doc_data,\n",
    "            mime_type=\"application/pdf\",\n",
    "        ),\n",
    "        llm_pdf_parsing_promt,\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini 2.5 pro is facing overloading issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pdf_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "base64_string = base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"file\",\n",
    "                    \"file\": {\n",
    "                        \"filename\": pdf_path,\n",
    "                        \"file_data\": f\"data:application/pdf;base64,{base64_string}\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Parse all of the text from this image into a Markdown format.\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4o is refusing the prompt with \"I'm sorry, I can't assist with that\" or \"I'm unable to directly parse the entire PDF content here\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_base64_images(\n",
    "    pdf_path: Path, image_format: str = \"PNG\", dpi: int = 350\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Convert each page of a PDF to a base64 encoded image.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        image_format (str): Format to save the images as (PNG, JPEG, etc.)\n",
    "        dpi (int): DPI resolution for the images\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of base64 encoded strings, one for each page\n",
    "    \"\"\"\n",
    "    # Convert PDF to list of PIL Image objects\n",
    "    images = convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "    # Encode each image to base64\n",
    "    base64_images = []\n",
    "    for i, image in enumerate(images):\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=image_format)\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "        base64_images.append(img_str)\n",
    "\n",
    "    return base64_images\n",
    "\n",
    "\n",
    "pdf_images = pdf_to_base64_images(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsedPDFText(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Parse all of the text from this image into a Markdown format.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{pdf_images[1]}\",\n",
    "                        \"detail\": \"high\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format=ParsedPDFText,\n",
    "    temperature=0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.parsed.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4o mini works very well if we use images instead of PDFs and apply structured outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 4.1 nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_images = pdf_to_base64_images(test_pdf)\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4.1-nano-2025-04-14\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Parse all of the text from this image into a Markdown format.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{pdf_images[1]}\",\n",
    "                        \"detail\": \"high\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format=ParsedPDFText,\n",
    "    temperature=0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.parsed.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4.1 nano doesn't apply Markdown format properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 4.1 mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_images = pdf_to_base64_images(test_pdf)\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Parse all of the text from this image into a Markdown format.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{pdf_images[1]}\",\n",
    "                        \"detail\": \"high\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format=ParsedPDFText,\n",
    "    temperature=0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.parsed.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4.1 mini has a better output quality than GPT 4o mini (less changes to the original text), while having a similar speed and price!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_images = pdf_to_base64_images(test_pdf)\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Parse all of the text from this image into a Markdown format.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{pdf_images[1]}\",\n",
    "                        \"detail\": \"high\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format=ParsedPDFText,\n",
    "    temperature=0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.parsed.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 4.1 might be an overkill, given that the mini version seems to work well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LlamaParse\n",
    "\n",
    "Seems to work very well in the premium version, which costs $0.045 USD per page. Can also use the auto mode, which uses the premium mode only when a page is thought to need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parser\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    # auto_mode=True,  # automatically choose the best model for the input; doesn't always work well though\n",
    "    premium_mode=True,  # use premium models\n",
    ")\n",
    "\n",
    "# use SimpleDirectoryReader to parse our file\n",
    "file_extractor = {\".pdf\": parser}\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[pdf_path], file_extractor=file_extractor\n",
    ").load_data()\n",
    "display(Markdown(\"\\n\\n\".join([doc.text for doc in documents])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes messes up the order of the text, when it has multiple columns, and it can be expensive (e.g. $27 for 600 pages). But I also get $10 of free credit per month. A benefit here is that the output is separated by page, which can be useful for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMuPDF4LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = pymupdf4llm.to_markdown(pdf_path)\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output quality here is disappointing. Gaps between words, cut out text, disorganized layout, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "\n",
    "LlamaParse has the best output quality, but it's also the most expensive. Marker is a good alternative, with a slightly worse output quality but a much lower price. If I see that Marker's output quality starts to significantly harm the analysis, I might consider using LlamaParse instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
